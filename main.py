
# -*- coding: utf-8 -*-
"""PEML22.11.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1BKlXRgewUMMxZaN1Ueoce2QDez4QUifk

# data analysieren
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

# 读取数据
data = pd.read_csv('Concrete_Data_Yeh.csv')

# 查看数据的前几行
print(data.head())

# 查看数据的基本信息
print(data.info())

# 查看数据的描述性统计
print(data.describe())

# 可视化数据之间的关系（相关性矩阵）
plt.figure(figsize=(12, 8))
sns.heatmap(data.corr(), annot=True, cmap='coolwarm', fmt='.2f')
plt.title('Correlation Heatmap')
plt.show()

"""# Ausreißer analysieren"""

# 使用箱线图检查每个特征的异常值
plt.figure(figsize=(12, 8))
sns.boxplot(data=data)
plt.xticks(rotation=90)
plt.title('Boxplot for Feature Outliers')
plt.show()

"""# Ausreißer entfernen"""

# 使用IQR方法去除异常值
Q1 = data.quantile(0.25)
Q3 = data.quantile(0.75)
IQR = Q3 - Q1

# 过滤掉超出1.5 * IQR范围的异常值
data_clean = data[~((data < (Q1 - 1.5 * IQR)) | (data > (Q3 + 1.5 * IQR))).any(axis=1)]

# 查看去除异常值后的数据
print(data_clean.shape)

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

# 计算相关性矩阵
corr_matrix = data_clean.corr()

# 使用seaborn绘制热力图
plt.figure(figsize=(10, 8))  # 可以调整图形大小
sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt='.2f', cbar=True)

# 显示图形
plt.title('Correlation Heatmap After Outlier Removal')
plt.show()

"""## Modulle erstellen

解释：
残差图：

使用 sns.residplot() 绘制残差图，lowess=True 表示添加局部加权回归线（帮助检测模式）。
如果残差图没有明显的模式（比如呈现随机散布），则模型的拟合效果较好。
预测值与实际值的对比图：

使用 plt.scatter() 绘制每个预测值与实际值的散点图。
红色的直线表示理想情况下，预测值和实际值应该完全一致，即所有点应该沿着这条对角线分布。
结果展示：
残差图：展示了残差是否在所有预测值上均匀分布。如果有明显的模式（例如 U 形状），可能意味着模型没有完全捕捉到数据中的关系。

预测值与实际值的对比图：展示了预测值与实际值的关系。点越接近红线，表示模型越准确。
"""

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression, Ridge, Lasso
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.svm import SVR
from sklearn.neighbors import KNeighborsRegressor
from sklearn.neural_network import MLPRegressor
from sklearn.preprocessing import PolynomialFeatures
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import pandas as pd

# 将数据分为特征和目标变量
X = data_clean[['cement', 'slag', 'flyash', 'water', 'superplasticizer', 'coarseaggregate', 'fineaggregate', 'age']]
y = data_clean['csMPa']

# 数据分割为训练集和测试集
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# 创建多项式特征（2级） - 仅用于多项式线性回归
poly = PolynomialFeatures(degree=2)  # 设置多项式的度数为2
X_poly_train = poly.fit_transform(X_train)
X_poly_test = poly.transform(X_test)

# 创建模型
models = {
    'Polynomial Linear Regression (Degree 2)': LinearRegression(),  # 使用多项式回归
    'Ridge Regression': Ridge(),
    'Lasso Regression': Lasso(),
    'Decision Tree Regression': DecisionTreeRegressor(),
    'Random Forest Regression': RandomForestRegressor(),
    'Gradient Boosting Regression': GradientBoostingRegressor(),
    'Support Vector Regression': SVR(),
    'K-Nearest Neighbors Regression': KNeighborsRegressor(),
    'Neural Network Regression': MLPRegressor(hidden_layer_sizes=(100,), max_iter=1000, random_state=42)
}

# 创建空字典存储模型的性能
performance = {
    'Model': [],
    'MAE': [],
    'RMSE': [],
    'R^2 Score': []
}

# 训练和评估每个模型
for model_name, model in models.items():
    # 对于多项式线性回归，使用多项式特征
    if model_name == 'Polynomial Linear Regression (Degree 2)':
        model.fit(X_poly_train, y_train)  # 用多项式特征训练模型
        y_pred = model.predict(X_poly_test)  # 在测试集上预测
    else:
        model.fit(X_train, y_train)  # 对于其他模型，直接使用原始特征训练
        y_pred = model.predict(X_test)  # 在测试集上预测

    # 计算MAE、RMSE、R²并保存到字典
    performance['Model'].append(model_name)
    performance['MAE'].append(mean_absolute_error(y_test, y_pred))
    performance['RMSE'].append(mean_squared_error(y_test, y_pred, squared=False))  # RMSE是MSE的平方根
    performance['R^2 Score'].append(r2_score(y_test, y_pred))

# 转换字典为DataFrame
performance_df = pd.DataFrame(performance)

# 显示表格
print(performance_df)

import joblib

# 选择随机森林模型作为最佳模型
best_model = RandomForestRegressor()
best_model.fit(X_train, y_train)

# 保存模型为.pkl文件
joblib.dump(best_model, "random_forest_model.pkl")
print("模型已保存为 random_forest_model.pkl")
